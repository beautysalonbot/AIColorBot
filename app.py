# === app.py =========================================================
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookParser
from linebot.models import (
    MessageEvent, ImageMessage, TextMessage, TextSendMessage,
    QuickReply, QuickReplyButton, MessageAction
)
from dotenv import load_dotenv
import os, sys, traceback, cv2, numpy as np, pandas as pd
from sklearn.neighbors import NearestNeighbors
from collections import defaultdict
import openai

# ---------- env èª­ã¿è¾¼ã¿ ----------
load_dotenv()
CHANNEL_SECRET       = os.getenv("CHANNEL_SECRET")
CHANNEL_ACCESS_TOKEN = os.getenv("CHANNEL_ACCESS_TOKEN")
openai.api_key       = os.getenv("OPENAI_API_KEY")

print("Loaded env:", CHANNEL_SECRET[:5] if CHANNEL_SECRET else "None",
      openai.api_key[:5] if openai.api_key else "None")

# ---------- LINE åˆæœŸåŒ– ----------
app          = Flask(__name__)
line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
parser       = WebhookParser(CHANNEL_SECRET)

# ---------- kNN æº–å‚™ ----------
df  = pd.read_csv("recipes.csv")
X   = df[["L", "a", "b"]].values
knn = NearestNeighbors(n_neighbors=3).fit(X)

user_state = defaultdict(dict)   # user_id â†’ {step, img, lv}

def extract_lab(img_bytes):
    nparr = np.frombuffer(img_bytes, np.uint8)
    img   = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    lab   = cv2.cvtColor(img, cv2.COLOR_BGR2LAB).reshape(-1,3).mean(axis=0)
    return lab

# ================= callback =================
@app.route("/callback", methods=["POST"])
def callback():
    sig  = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)
    try:
        events = parser.parse(body, sig)
    except Exception:
        abort(400)

    for ev in events:
        # ---------- â‘  ç”»åƒ ----------
        if isinstance(ev, MessageEvent) and isinstance(ev.message, ImageMessage):
            content = line_bot_api.get_message_content(ev.message.id)
            uid = ev.source.user_id
            user_state[uid] = {"step":"ask_lv", "img":content.content}

            line_bot_api.reply_message(
                ev.reply_token,
                TextSendMessage(text="ç¾åœ¨ã®æ˜åº¦ã‚’ 0ã€œ19 ã®æ•°å­—ã§é€ã£ã¦ãã ã•ã„ğŸ“©")
            )
            print("ğŸ“· img recv:", uid)
            return "OK", 200

        # ---------- â‘¡ ãƒ†ã‚­ã‚¹ãƒˆ ----------
        if isinstance(ev.message, TextMessage):
            text = ev.message.text
            uid  = ev.source.user_id
            st   = user_state.get(uid, {})

            # --- LV å—ä»˜ ---
            if st.get("step")=="ask_lv":
                try:
                    lv = int(text)
                    if not 0<=lv<=19: raise ValueError
                except ValueError:
                    line_bot_api.reply_message(
                        ev.reply_token,
                        TextSendMessage(text="0ã€œ19 ã®æ•°å­—ã§é€ã£ã¦ãã ã•ã„â—")
                    )
                    return "OK",200

                st["lv"]=lv; st["step"]="ask_hist"
                quick = QuickReply(items=[
                    QuickReplyButton(action=MessageAction(label="ãƒ–ãƒªãƒ¼ãƒãªã—", text="HIST:0")),
                    QuickReplyButton(action=MessageAction(label="ãƒ–ãƒªãƒ¼ãƒ1å›", text="HIST:1")),
                    QuickReplyButton(action=MessageAction(label="ãƒ–ãƒªãƒ¼ãƒ2å›", text="HIST:2")),
                    QuickReplyButton(action=MessageAction(label="ç¸®æ¯›ã‚ã‚Š",   text="HIST:S")),
                ])
                line_bot_api.reply_message(
                    ev.reply_token,
                    TextSendMessage(text="ãƒ–ãƒªãƒ¼ãƒã‚„ç¸®æ¯›ã®å±¥æ­´ã¯ï¼Ÿ", quick_reply=quick)
                )
                print("ğŸ“ lv recv:", lv)
                return "OK",200

            # --- å±¥æ­´å—ä»˜ & GPT ---
            if text.startswith("HIST:") and st.get("step")=="ask_hist":
                hist = text.split(":")[1]
                lv   = st["lv"]; lab = extract_lab(st["img"])

                df["lv_diff"]  = (df["L"]-lv*12).abs()
                df["hist_pen"] = (df["formula"].str.contains("6%")&(hist=="S")).astype(int)
                df["score"]    = df["lv_diff"]*0.5 + df["hist_pen"]*10
                top3 = df.nsmallest(3,"score")

                replies=[]
                for r in top3.itertuples():
                    prompt=(f"ä»¥ä¸‹ã®ãƒ˜ã‚¢ã‚«ãƒ©ãƒ¼å‡¦æ–¹ã‚’ç¾å®¹å¸«ã‚‰ã—ãä¸€è¨€ã§è§£èª¬ã—ã¦ã€‚\n"
                            f"å‡¦æ–¹: {r.formula}\n40æ–‡å­—ä»¥å†…ã€æ—¥æœ¬èªã€‚")
                    try:
                        rsp=openai.ChatCompletion.create(
                            model="gpt-4o-mini",
                            messages=[{"role":"user","content":prompt}],
                            max_tokens=60,temperature=0.7
                        )
                        comment=rsp.choices[0].message.content.strip()

                    except Exception as e:
                        print("GPT Error:",type(e).__name__,"-",e,file=sys.stderr)
                        traceback.print_exc()
                        comment="(è§£èª¬å–å¾—ã‚¨ãƒ©ãƒ¼)"

                    replies.append(f"{r.name}\n{r.formula}\n{comment}")

                line_bot_api.reply_message(
                    ev.reply_token,
                    TextSendMessage(text="\n\n".join(replies))
                )
                print("âœ… done:", uid)
                user_state.pop(uid,None)
                return "OK",200

    return "OK",200   # fallback

# ---------- Verify ç”¨ GET ----------
@app.route("/callback", methods=["GET"])
def health_check():
    return "OK",200

# ---------- èµ·å‹• ----------
if __name__=="__main__":
    port=int(os.environ.get("PORT",5000))
    app.run(host="0.0.0.0",port=port)
# ================================================================
